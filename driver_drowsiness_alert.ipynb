{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from pygame import mixer \n",
    "import dlib # python api for face recognition model\n",
    "from math import hypot # to get the length of hor and vert lines we have used hypot function from math lib\n",
    "\n",
    "mixer.init()\n",
    "sound = mixer.Sound('Buzz1.wav') #sound for the alarm\n",
    "\n",
    "cap= cv2.VideoCapture(0) # capture video with value 0 because we are using laptop's webcam\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL #set the font type of the text displayed\n",
    "\n",
    "detector = dlib.get_frontal_face_detector() # we have created an object \"detector\" which will return the default face detector.\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") \n",
    "# we have downloaded shape predictor 68 face shape predictor which runs on the input image\n",
    "#and returns a single full_object_detection.\n",
    "\n",
    "blink = 0\n",
    "TOTAL = 0\n",
    "Thresh = 5\n",
    "Consec_frames= 10\n",
    "Counter = 0\n",
    "def midpoint(p1 ,p2):  #basic function to find the midpoint\n",
    "          return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)\n",
    "    \n",
    "def get_blinking_ratio(eye_points, facial_landmarks): # funtion to detect the blinking ratio.\n",
    "    \n",
    "            left_point = (facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y) # 0 is the index value of 42\n",
    "            right_point = (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y) # 3 is the index value of 45\n",
    "            center_top = midpoint(facial_landmarks.part(eye_points[1]), facial_landmarks.part(eye_points[2])) # 1, 2 are the index value of43,44\n",
    "            center_bottom = midpoint(facial_landmarks.part(eye_points[5]), facial_landmarks.part(eye_points[4])) # 5,4 are the index value of 47,46\n",
    "            \n",
    "            hor_line = cv2.line(frame, left_point, right_point, (0, 255, 0), 2)\n",
    "            ver_line = cv2.line(frame, center_top, center_bottom, (0, 255, 0), 2)\n",
    "                \n",
    "            # this will draw horizontal and vertical line on the eye    \n",
    "            hor_line_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "            ver_line_length = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))          \n",
    "            \n",
    "            ratio = hor_line_length / ver_line_length # finding ratio\n",
    "            return ratio\n",
    "        \n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    gray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # here we are converting frame from BGR to GRAY\n",
    "    \n",
    "    faces= detector(gray) # the object faces will detect the frontal face in GRAY scale. \n",
    "    \n",
    "    for face in faces:\n",
    "        \n",
    "        landmarks = predictor(gray, face) # convert the resultant landmarks to a NumPy array\n",
    "        # detect blinking\n",
    "        left_eye_ratio = get_blinking_ratio([36,37,38,39,40,41], landmarks) \n",
    "      \n",
    "        right_eye_ratio = get_blinking_ratio([42,43,44,45,46,47], landmarks) \n",
    "        \n",
    "        cv2.putText(frame, \"left ratio: {:.2f}\".format(left_eye_ratio), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"right ratio: {:.2f}\".format(right_eye_ratio), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "        if left_eye_ratio > Thresh and right_eye_ratio > Thresh:# left eye and right eye ratio is compared with the thresh i.e,5.\n",
    "            if blink == 0 : # under nested if condition the timer will start when the eye is open\n",
    "                start_time = time.time()\n",
    "                blink = 1 # when the first blink happens\n",
    "            if time.time() - start_time > 0.3: # if time is exceeding the average eye closing time which is 0.3 seconds\n",
    "                Counter += 1 # then the frame counter will exceed by one\n",
    "            if Counter >= Consec_frames:# when the counter >= Consec_frames which is defined  with value 10\n",
    "                sound.play() #play the alarm\n",
    "                cv2.putText(frame,'ALERT!!!',(100,100), font, 4,(0,0,255),4,cv2.LINE_AA) # throw ALERT message.\n",
    "                \n",
    "        else:\n",
    "            Counter = 0\n",
    "            \n",
    "        cv2.imshow(\"Frame\", frame) # to display the resulting frame\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): #wait time is 30 sec and if will press key q the video will be stopped.\n",
    "        break # and get back to while loop again with new frame.\n",
    "\n",
    "        \n",
    "cap.release() # when everything is fine it will relaese the video\n",
    "cv2.destroyAllWindows()      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
